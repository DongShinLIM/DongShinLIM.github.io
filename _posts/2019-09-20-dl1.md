---
title: 'Deep Learning'
date: 2019-09-20 00:00:00
featured_image: '/images/demo/dl.jpg'
excerpt: A first look at a neural network
---

### MNIST dataset을 기본적인 딥러닝 알고리즘 구현하기
MNIST는 머신러닝에서 고전으로 취급 받는 흑백 손글씨 데이터셋이다. 숫자 이미지(28×28픽셀)를 10개의 범주(0부터 9까지)로 분류하는 문제로써
6만개의 훈련 이미지와 1만 개의 테스트 이미지로 구성되어 있다. MNIST 데이터셋은 넘파이 배열 형태로 케라스에 포함되어 있습니다.


![](/images/demo/mnist.PNG)

```python
from keras.datasets import mnist

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
```

    Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz
    11493376/11490434 [==============================] - 5s 0us/step


### Train dataset, Test dataset, validation dataset
train_images와 train_labels가 모델이 학습해야 할 훈련 세트를 구성하고 test_images와 test_labels로 구성 된 테스트셋에서 테스트 될 것입니다.
훈련데이터를 살펴보면

```python
train_images.shape
```
    (60000, 28, 28)


```python
len(train_labels)
```

    60000


```python
train_labels
```

    array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)

테스트 데이터는 이렇습니다.

```python
test_images.shape
```

    (10000, 28, 28)


```python
len(test_labels)
```

    10000


```python
test_labels
```

    array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)



#### 작업순서는 다음과 같습니다.
- 훈련 데이터 train_images와 train_labels를 네트워크에 주입합니다.
- 네트어크는 레이블을 연관시킬 수 있도록 학습됩니다.
- test_images에 대한 예측을 네트워크에 요청합니다.
- 예측된 레이블이 test_labels와 맞는지 확인합니다.


```python
from keras import models
from keras import layers

network = models.Sequential()
network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))
network.add(layers.Dense(10, activation='softmax'))
```

#### Architecture of Deep Neural Networks
- 신경망의 핵심 구성요소는 일정의 데이터 처리 필터라고 생각 할 수 있는 층(layer)입니다. 어떠한 데이터가 들어가면 더 유용한 형태로 출력됩니다.
- 조금 더 구체적으로 층은 주어진 문제에 더 의미 있는 표현(representation)을 입력 된 데이터로부터 추출합니다.
- 대부분의 딥러닝은 간단 한 층을 연결하여 구성되어 있고, 점차 데이터를 정제하는 형태를 가지고 있습니다 

**Example**: 
- 여기서는 완전연결(fully connected)된 신경망 층인 Dense층 2개가 연속되어 있습니다. 
- 두 번째 층은 10개의 확률 점수가 들어있는 배열을 반환하는 소프트맥스(softmax)층 입니다.
- 각 점수는 현재 숫자 이미지가 10개의 숫자 클래스중 하나에 속할 확률 입니다. 

#### 신경망이 훈련 준비를 마치기 위해서는 컴파일 단계에 포함 될 세가지가 더 필요합니다. 

* 손실함수: 예측값과 실제 값의 차이를 계산하는 함수입니다. 훈련 데이터에서 신경망의 성능을 측정하는 방법으로 네트위크가 옳은 방향으로 학습될 수 있도록 도와줍니다.
* 옵티마이저: 입련된 데이터와 손실함 수를 기반으로 네트워크 weight를 업데이트 하는 메커니즘입니다.
* 훈련과 테스트 과정을 모니터링 할 지표 : 정확도(정확히 분류된 이미지의 비율)만 고려


```python
network.compile(optimizer='rmsprop',
                loss='categorical_crossentropy',
                metrics=['accuracy'])
```

#### Preprocessiong
- 훈련을 시작하기 전에 데이터를 네트워크에 맞는 크기로 바꾸고 모든 값을 0과 1사이로 스케일을 조정합니다.

예를 들어 우리의 훈련 이미지는 [0.255]사이의 값인 unit8 타입의 (60000, 28, 28)크기를 가진 배열로 저장되어 있으니 
이 데이터를 0과 1사이의 값을 가지는 float32타입의 (60000, 28×28)크기인 배열로 바꿔줍니다.


```python
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype('float32') / 255

test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype('float32') / 255
```
레이블을 범주형으로 인코딩 해야하는 것도 필요합니다.


```python
from keras.utils import to_categorical

train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)
```
이제 신경망을 훈련시킬 준비가 되었습니다. 케라스에서 fit 메서드를 호출하여 훈련 데이터에 모델을 학습시킵니다.


```python
network.fit(train_images, train_labels, epochs=5, batch_size=128)
```
epochs : 내 뉴럴넷이 전체 데이터를 몇 번 봤는지를 의미합니다.
batch_size(mini_batch) : 몇 개씩 묶어서 도출 된 loss값을 가지고 weight를 업데이트 하는지르 의미합니다.
iteration : 전체 데이터 / batch_size 이며, 이 예에서는 60,000/128 = 469 를 의미합니다.


    WARNING:tensorflow:From /Users/jonathanlim/project/keras_talk/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.
    
    Epoch 1/5
    60000/60000 [==============================] - 1s 22us/step - loss: 0.2540 - accuracy: 0.9266
    Epoch 2/5
    60000/60000 [==============================] - 1s 20us/step - loss: 0.1016 - accuracy: 0.9700
    Epoch 3/5
    60000/60000 [==============================] - 1s 19us/step - loss: 0.0678 - accuracy: 0.9803
    Epoch 4/5
    60000/60000 [==============================] - 1s 19us/step - loss: 0.0496 - accuracy: 0.9852
    Epoch 5/5
    60000/60000 [==============================] - 1s 19us/step - loss: 0.0375 - accuracy: 0.9886





    <keras.callbacks.callbacks.History at 0x137425828>


훈련하는 동안 2개의 정확도가 출력됩니다. 훈련 데이터에 대한 네트워크 손실과 정확도입니다.
훈련 데이터에 대하여 98.9%의 정확도를 금방 달성하는 것을 볼 수 있습니다. 이제 테스트 셋에서도 모델이 잘 작동하는지 확인해보겠습니다.


```python
test_loss, test_acc = network.evaluate(test_images, test_labels)
```

    10000/10000 [==============================] - 0s 17us/step



```python
print('test_acc:', test_acc)
```

    test_acc: 0.9803000092506409

테스트 셋의 정확도는 98%로 나왔습니다. 훈련 세트 정확도보다 약간 떨어지는 이유는 과적합(overfitting)때문 입니다. 



